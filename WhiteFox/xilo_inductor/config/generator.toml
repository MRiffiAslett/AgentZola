[sut]
name = "inductor"
framework = "pytorch"

[paths]
prompt_dir = "prompts"
output_dir = "generated-outputs"
hf_home = "hf_cache"
log_file = "whitefox-llm-gen.log"
bandit_state_file = "whitefox_state.json"

[model]
name = "bigcode/starcoder"
dtype = "float16"
max_model_len = 8192
gpu_memory_utilization = 0.85
swap_space = 4

[generation]
num_samples = 1
max_tokens = 4096
temperature = 1.0
top_p = 1.0
split_size = 20
unit_num = 2
optimizations_dir = "xilo_inductor/artifacts/Prompts/test"
tests_per_optimization = 10
tests_per_iteration = 5
max_iterations = 15
examples_per_prompt = 3
test_timeout = 30
parallel_test_workers = 4
parallel_optimizations = 2

# TODO: Add PyTorch Inductor specific optimizations
optimizations = []

[prompts]
feedback_instruction = ""

[stopping]
eof_strings = [
    "<|endoftext|>",
    "###",
    "__output__ =",
    "if __name__",
    '"""',
    "'''",
    "# Model ends",
]

[oracles]
float_rtol = 1e-5
float_atol = 1e-8

allowed_errors = []

[pass_name_aliases]
# TODO: Add PyTorch Inductor pass name aliases
