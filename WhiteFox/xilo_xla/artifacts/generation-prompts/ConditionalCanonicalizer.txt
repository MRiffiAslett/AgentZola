### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `ReshapeReshapeForwarding` in TensorFlow XLA.

# Description
The model should contain the following pattern:
```
t1 = tf.reshape(input_tensor, ...)
t2 = tf.reshape(t1, input_tensor.shape)
```
The pattern describes that there are two reshape operators in the model. The first `reshape` operator transforms a tensor input `input_tensor` from `input_tensor.shape` to any new shape, and the second `reshape` operator transforms the output of first `reshape` back to `input_tensor.shape`.


# Model
class Model(tf.keras.Model):

  def __init__(self):
    super(Model, self).__init__()

  def call(self, x1):
    x2 = tf.reshape(x1, [2,2])
    return tf.reshape(x2, [4])

# Initializing the model
m = Model()

# Inputs to the model
input_shape = [4]
x1 = tf.constant([4.,5.,6.,7.], shape=input_shape)

# Call model
y = m(x1)




### Description for `ReshapeReshapeForwarding` Optimization Trigger Characteristics

For the `ReshapeReshapeForwarding` optimization pass in TensorFlow XLA to be triggered, the TensorFlow model must exhibit a specific pattern of reshape operations. This pattern involves two sequential reshape operations where the output shape of the second reshape operation matches the input shape of the tensor being reshaped by the first operation. Specifically:

- The first reshape operation changes the shape of an input tensor to any arbitrary new shape.
- The second reshape operation immediately follows the first and changes the tensor back to its original shape.

Here is a code example that illustrates this pattern:

```python
import tensorflow as tf

# Input tensor of shape (2, 3)
input_tensor = tf.constant([[1, 2, 3], [4, 5, 6]])

# First reshape operation: change shape
t1 = tf.reshape(input_tensor, [6])

# Second reshape operation: revert to original shape
t2 = tf.reshape(t1, input_tensor.shape)

# t2 will have the same shape as input_tensor, triggering the optimization
```

### Description for `ConditionalCanonicalizer` Optimization Trigger Characteristics

The `ConditionalCanonicalizer` optimization pass is triggered in TensorFlow models that use conditional operations (`tf.cond` in TensorFlow or `kConditional` in XLA) where the inputs, outputs, or the computations within the branches of the conditional are not already in tuple form. The optimization aims to standardize these elements by ensuring they are all in tuple form. Characteristics that trigger this optimization include:

1. **Non-Tuple Branch Inputs**: Any branch of the conditional operation receives non-tuple inputs.
2. **Non-Tuple Branch Outputs**: Any branch of the conditional operation produces non-tuple outputs.
3. **Non-Tuple Conditional Operands (Excluding the Predicate)**: If any operand (excluding the predicate) of the conditional operation is not a tuple.
4. **Non-Tuple Conditional Output**: The output of the conditional operation itself is not a tuple.

Here is a TensorFlow code example to illustrate these patterns:

```python
# Conditional operation with non-tuple inputs and outputs
x = tf.constant(10)
y = tf.constant(20)

def f1(): return x * y
def f2(): return x + y

# The branches f1 and f2 return non-tuple outputs, and the inputs x and y are non-tuple.
result = tf.cond(tf.less(x, y), f1, f2)

# This setup will trigger the ConditionalCanonicalizer optimization to wrap inputs and outputs into tuples.
```

In summary, to trigger `ConditionalCanonicalizer`, the TensorFlow XLA model needs to use conditional operations where any of the inputs, outputs, or internal operations of branches are not already in tuple format, prompting the optimization pass to convert them into tuples.