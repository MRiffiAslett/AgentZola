### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `ReshapeReshapeForwarding` in TensorFlow XLA.

# Description
The model should contain the following pattern:
```
t1 = tf.reshape(input_tensor, ...)
t2 = tf.reshape(t1, input_tensor.shape)
```
The pattern describes that there are two reshape operators in the model. The first `reshape` operator transforms a tensor input `input_tensor` from `input_tensor.shape` to any new shape, and the second `reshape` operator transforms the output of first `reshape` back to `input_tensor.shape`.


# Model
class Model(tf.keras.Model):

  def __init__(self):
    super(Model, self).__init__()

  def call(self, x1):
    x2 = tf.reshape(x1, [2,2])
    return tf.reshape(x2, [4])

# Initializing the model
m = Model()

# Inputs to the model
input_shape = [4]
x1 = tf.constant([4.,5.,6.,7.], shape=input_shape)

# Call model
y = m(x1)




### Characteristics for `ReshapeReshapeForwarding` Trigger

For the `ReshapeReshapeForwarding` optimization in TensorFlow XLA to be triggered, a TensorFlow model must have a specific pattern involving two consecutive `tf.reshape` operations. Hereâ€™s the characteristic pattern:

1. An initial tensor is reshaped into a new shape.
2. This newly shaped tensor is then immediately reshaped back into its original shape.

This optimization would be triggered when the output shape of the second reshape operation matches the input shape of the tensor that was input to the first reshape operation. 

#### Example Code:
```python
import tensorflow as tf

# Define an input tensor
input_tensor = tf.random.normal([10, 20])

# First reshape operation
t1 = tf.reshape(input_tensor, [200])

# Second reshape operation that restores the original shape
t2 = tf.reshape(t1, [10, 20])

# t2 can be optimized back to input_tensor directly
```

### Characteristics for `ZeroSizedHloElimination` Trigger

The `ZeroSizedHloElimination` optimization is triggered when there are operations within the model that produce zero-sized tensors. These tensors have shapes where at least one dimension has a size of zero, resulting in no elements.

Here are the primary characteristics for this optimization to be triggered:

1. The operation must produce a zero-sized tensor, i.e., a tensor where the product of the dimensions equals zero.
2. The operation should not have significant side effects that must be preserved, with an exception for certain custom calls.
3. The tensor must be an array and must be statically sized.

Operations that typically might produce such outputs include incorrect reshaping, slicing, or operations contingent upon dynamic input shapes that resolve to zero at runtime.

#### Example Code:
```python
import tensorflow as tf

# Incorrect reshape that leads to a zero-sized tensor
input_tensor = tf.random.normal([10, 0])  # Zero-sized second dimension
reshaped_tensor = tf.reshape(input_tensor, [0, 100])  # Result is zero-sized

# Another example could involve slicing where the slice size is zero
sliced_tensor = tf.slice(input_tensor, [0, 0], [10, 0])  # Zero-sized slice
```
In these cases, TensorFlow XLA can potentially eliminate these operations or replace them with constant tensors, optimizing runtime execution and memory usage.