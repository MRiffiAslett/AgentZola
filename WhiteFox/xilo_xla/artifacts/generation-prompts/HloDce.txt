### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `ReshapeReshapeForwarding` in TensorFlow XLA.

# Description
The model should contain the following pattern:
```
t1 = tf.reshape(input_tensor, ...)
t2 = tf.reshape(t1, input_tensor.shape)
```
The pattern describes that there are two reshape operators in the model. The first `reshape` operator transforms a tensor input `input_tensor` from `input_tensor.shape` to any new shape, and the second `reshape` operator transforms the output of first `reshape` back to `input_tensor.shape`.


# Model
class Model(tf.keras.Model):

  def __init__(self):
    super(Model, self).__init__()

  def call(self, x1):
    x2 = tf.reshape(x1, [2,2])
    return tf.reshape(x2, [4])

# Initializing the model
m = Model()

# Inputs to the model
input_shape = [4]
x1 = tf.constant([4.,5.,6.,7.], shape=input_shape)

# Call model
y = m(x1)




### Characteristics of TensorFlow Model for `ReshapeReshapeForwarding` Optimization

The TensorFlow XLA optimization pass `ReshapeReshapeForwarding` is triggered when a specific pattern of tensor reshaping operations is detected in the model. Here are the characteristics:

1. **Sequential Reshape Operations**: The model must contain two consecutive `tf.reshape` operations.
2. **Redundant Reshaping**: The second reshape operation must revert the tensor back to its original shape, which was the shape before the first reshape. This effectively means that the two reshape operations cancel each other out.

#### Example Code Pattern:
```python
import tensorflow as tf

# Input tensor of any shape
input_tensor = tf.random.normal([8, 16])

# First reshape operation changing the shape of input_tensor
t1 = tf.reshape(input_tensor, [4, 32])

# Second reshape operation reverting the shape back to the original
t2 = tf.reshape(t1, [8, 16])
```
In this example, `t1` is reshaped from `[8, 16]` to `[4, 32]`, and then `t2` is reshaped back to `[8, 16]`. This pattern triggers the `ReshapeReshapeForwarding` optimization, where the two reshape operations are recognized as redundant and can be optimized out, directly using `input_tensor` for any further computations instead of `t2`.

### Characteristics of TensorFlow Model for `HloDCE` Optimization

The `HloDCE` (Dead Code Elimination) optimization pass in TensorFlow XLA is triggered when there are computations or operations in the model that do not affect the final output. The optimization aims to remove such unnecessary operations, improving the efficiency of the model. Here are the characteristics that trigger this optimization:

1. **Unused Outputs**: Operations or computations that produce outputs which are not used anywhere in the computation graph.
2. **Side Effect Free**: The operations must be free of side effects unless they meet specific conditions (like being marked explicitly as removable despite having side effects).
3. **Dead Roots**: Instructions that are roots of computations but don't contribute to the final outputs of the module.
4. **Dead Parameters**: Parameters that are not used in the computations.

#### Example Code Pattern:
```python
import tensorflow as tf

# Input tensor
input_tensor = tf.random.normal([10, 10])

# Operation whose output is not used
unused_output = tf.square(input_tensor)

# Main computation
result = tf.reduce_sum(input_tensor)
```
In this example, the `tf.square(input_tensor)` operation is an unused output since `unused_output` is never used in any subsequent computation. This operation can be eliminated by the `HloDCE` optimization pass, as it does not contribute to the final result (`result`).

These patterns, when detected by TensorFlow XLA, lead to optimizations that simplify the model by removing redundant operations and unused computations, thus potentially speeding up the model's execution and reducing resource consumption.