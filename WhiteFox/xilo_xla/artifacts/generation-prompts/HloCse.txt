### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `ReshapeReshapeForwarding` in TensorFlow XLA.

# Description
The model should contain the following pattern:
```
t1 = tf.reshape(input_tensor, ...)
t2 = tf.reshape(t1, input_tensor.shape)
```
The pattern describes that there are two reshape operators in the model. The first `reshape` operator transforms a tensor input `input_tensor` from `input_tensor.shape` to any new shape, and the second `reshape` operator transforms the output of first `reshape` back to `input_tensor.shape`.


# Model
class Model(tf.keras.Model):

  def __init__(self):
    super(Model, self).__init__()

  def call(self, x1):
    x2 = tf.reshape(x1, [2,2])
    return tf.reshape(x2, [4])

# Initializing the model
m = Model()

# Inputs to the model
input_shape = [4]
x1 = tf.constant([4.,5.,6.,7.], shape=input_shape)

# Call model
y = m(x1)


### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `AllReduceCombiner` in TensorFlow XLA.

### Characteristics for Triggering `ReshapeReshapeForwarding` in TensorFlow XLA:

The TensorFlow model must include a sequence where a tensor undergoes two consecutive `reshape` operations, where the second reshape operation reverses the shape change performed by the first reshape. Specifically, the second reshape operation must transform the tensor back to its original shape. This sequence is redundant as the net effect is that the tensor retains its initial shape, making the reshapes unnecessary.

**Code Example Illustration:**
```python
import tensorflow as tf

# Assuming 'input_tensor' is a predefined tensor with a specific shape
# First reshape: Change the shape of 'input_tensor'
t1 = tf.reshape(input_tensor, new_shape)

# Second reshape: Revert to the original shape of 'input_tensor'
t2 = tf.reshape(t1, tf.shape(input_tensor))

# 't2' should essentially be the same as 'input_tensor'
```

### Characteristics for Triggering `HloCSE` (Common Subexpression Elimination) in TensorFlow XLA:

For the `HloCSE` optimization to be triggered, the TensorFlow model must contain identical `HloInstruction` instances, which can be eliminated without affecting the program's correctness. These redundant instructions must:

1. Perform the same operation.
2. Have identical operands and operation characteristics (like shape and dimensions if the layout is sensitive).
3. Must not be involved in operations with side effects or operations like `kPartitionId` and `kReplicaId` which are inherently unique.

This optimization is particularly useful in models where subgraphs or operations are repeated with the same inputs and parameters, allowing for the consolidation of these operations into a single instance, reducing computational redundancy.

**Code Example Illustration:**
```python
import tensorflow as tf

# Example tensor and operations
x = tf.constant([1.0, 2.0, 3.0])
y = tf.constant([1.0, 2.0, 3.0])

# Identical operations on identical inputs
z1 = tf.add(x, y)
z2 = tf.add(x, y)  # This operation is a candidate for elimination by HloCSE

# z2 can be replaced with z1, reducing redundancy
```

In this model, `z2` does exactly the same computation as `z1` and thus `z2` can be optimized out, pointing any of its consumers to `z1` instead. This optimization reduces memory and computation overhead.