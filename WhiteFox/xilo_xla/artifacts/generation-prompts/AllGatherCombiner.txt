### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `AllGatherCombiner` in TensorFlow XLA.

# Description
The optimization pass `AllGatherCombiner` in TensorFlow XLA is triggered by TensorFlow models that meet specific criteria related to the usage of the `AllGather` operation. Here are the characteristics of models that would cause this optimization to be activated, leading the `AllGatherCombiner::Run` function to return `true`:

1. **Multiple `AllGather` Operations**: The model should contain multiple `AllGather` operations. The optimization aims to combine these into a single, more efficient operation. The combination is beneficial when there are several `AllGather` operations that can be merged based on specific attributes such as gathered dimensions or data types.

2. **Same All-Gather Dimension (if combined by dimension)**: If the `combine_by_dim` flag is `true`, all `AllGather` operations considered for merging should gather data along the same dimension. This is checked by comparing the `all_gather_dimension` of each operation.

3. **Data Type Consistency (when not combining different data types)**: If the `combine_different_dtypes` flag is `false`, all `AllGather` operations must have the same data type to be eligible for combination.

4. **Thresholds**: The combined size of the `AllGather` operations must meet certain thresholds (`combine_threshold_in_bytes` and `combine_threshold_count`) for the optimization to be considered worthwhile. These thresholds ensure that the combination is beneficial in terms of computational and memory efficiency.

5. **Absence of Layout Constraints**: The model should not contain `AllGather` operations with layout constraints as these could complicate or invalidate the combining process.

6. **Computation Context**: The optimization avoids combining `AllGather` operations within computations that are part of a `while` loop if the `combine_while_loops` flag is `false`. This is to prevent potential complications in control flow structures.

7. **Consistent Replication and Device Settings**: The `AllGather` operations must share similar settings concerning replication groups, channel IDs, and whether global device IDs are used. These settings ensure that the combined operation can function correctly across multiple devices or replicas.

### Illustrative Code Example
Hereâ€™s a simplified Python example using TensorFlow and simulating conditions that might trigger this optimization:

```python
import tensorflow as tf

# Assume a distributed strategy context
strategy = tf.distribute.MirroredStrategy(devices=["GPU:0", "GPU:1"])

with strategy.scope():
    # Input tensors
    tensor1 = tf.ones([10, 100])
    tensor2 = tf.ones([10, 100])

    # Multiple AllGather operations
    gathered1 = tf.raw_ops.AllGatherV2(input=tensor1, group_size=2, axis=0)
    gathered2 = tf.raw_ops.AllGatherV2(input=tensor2, group_size=2, axis=0)

# This setup might trigger the AllGatherCombiner if other conditions (like thresholds) are met.
```

This TensorFlow code defines multiple `AllGather` operations which, under the right conditions (like identical `axis` and sufficient `group_size`), might be combined through the `AllGatherCombiner` optimization in an XLA compilation context.
