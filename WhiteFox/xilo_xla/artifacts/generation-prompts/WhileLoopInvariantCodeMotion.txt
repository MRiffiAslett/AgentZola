### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `ReshapeReshapeForwarding` in TensorFlow XLA.

# Description
The model should contain the following pattern:
```
t1 = tf.reshape(input_tensor, ...)
t2 = tf.reshape(t1, input_tensor.shape)
```
The pattern describes that there are two reshape operators in the model. The first `reshape` operator transforms a tensor input `input_tensor` from `input_tensor.shape` to any new shape, and the second `reshape` operator transforms the output of first `reshape` back to `input_tensor.shape`.


# Model
class Model(tf.keras.Model):

  def __init__(self):
    super(Model, self).__init__()

  def call(self, x1):
    x2 = tf.reshape(x1, [2,2])
    return tf.reshape(x2, [4])

# Initializing the model
m = Model()

# Inputs to the model
input_shape = [4]
x1 = tf.constant([4.,5.,6.,7.], shape=input_shape)

# Call model
y = m(x1)




### Characteristics of TensorFlow Model for `ReshapeReshapeForwarding` Optimization

The optimization `ReshapeReshapeForwarding` is triggered when the following pattern is identified in the model:

1. **Sequential Reshape Operations:** The model should contain a sequence of two reshape operations.
2. **Identity Reshape Pattern:** The output shape of the second reshape operation should match the input shape of the tensor input to the first reshape operation. Essentially, the second reshape undoes the transformation performed by the first reshape.

#### Example Code Pattern:
```python
import tensorflow as tf

# Input tensor of any shape
input_tensor = tf.random.normal([8, 8])

# First reshape transforms the shape
t1 = tf.reshape(input_tensor, [64])

# Second reshape reverts to the original shape
t2 = tf.reshape(t1, [8, 8])
```
In this example, the second reshape operation transforms the output of the first reshape (`t1`) back to the original shape of `input_tensor`. This pattern is what the `ReshapeReshapeForwarding` optimization targets to simplify by eliminating redundant reshape operations.

### Characteristics of TensorFlow Model for `WhileLoopInvariantCodeMotion` Optimization

The `WhileLoopInvariantCodeMotion` optimization is applied when certain conditions are met in models utilizing while loops:

1. **Invariant Operations Inside Loop:** There are operations within the while loop's body that produce the same value every iteration and can be moved outside the loop without affecting the loop's semantics.
2. **No Side-Effect Operations:** Operations that are candidates for hoisting should not have side effects.
3. **Memory Considerations:** The optimization checks that hoisting the operation does not lead to a disproportionate increase in memory usage, which is particularly important for operations that might significantly expand their output size compared to their input size (e.g., `Broadcast`, `Iota`).
4. **Control Dependencies:** Operations without control predecessors or successors are considered for hoisting.

#### Example Code Pattern:
```python
import tensorflow as tf

def loop_body(x):
    y = tf.constant([1.0, 2.0])  # Invariant operation
    z = x * y  # Dependent on x, not invariant
    return z

x = tf.constant([10.0, 20.0])
result = tf.while_loop(lambda x: tf.reduce_sum(x) < 1000, loop_body, [x])
```
In this example, the creation of tensor `y` is invariant (does not change across iterations) and can be moved outside the loop to optimize execution.

These optimizations significantly improve the efficiency of TensorFlow models by reducing redundant computations and memory usage, especially in complex models with nested operations and loops.