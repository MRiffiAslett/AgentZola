### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `ReshapeReshapeForwarding` in TensorFlow XLA.

# Description
The model should contain the following pattern:
```
t1 = tf.reshape(input_tensor, ...)
t2 = tf.reshape(t1, input_tensor.shape)
```
The pattern describes that there are two reshape operators in the model. The first `reshape` operator transforms a tensor input `input_tensor` from `input_tensor.shape` to any new shape, and the second `reshape` operator transforms the output of first `reshape` back to `input_tensor.shape`.


# Model
class Model(tf.keras.Model):

  def __init__(self):
    super(Model, self).__init__()

  def call(self, x1):
    x2 = tf.reshape(x1, [2,2])
    return tf.reshape(x2, [4])

# Initializing the model
m = Model()

# Inputs to the model
input_shape = [4]
x1 = tf.constant([4.,5.,6.,7.], shape=input_shape)

# Call model
y = m(x1)


### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `AllReduceCombiner` in TensorFlow XLA.

### Optimization Pass: `ReshapeReshapeForwarding`

#### Characteristics of a TensorFlow Model That Triggers This Optimization:

The `ReshapeReshapeForwarding` optimization is triggered when a TensorFlow model contains two consecutive `tf.reshape` operations where the second reshape operation reverses the shape change made by the first reshape operation. Specifically, the model should have the following characteristics:

1. **Sequential Reshape Operations:** There are two consecutive `tf.reshape` operations in the model.
2. **Shape Reversal:** The output shape of the second reshape operation matches the input shape of the tensor fed into the first reshape operation.

**Code Illustration:**
```python
import tensorflow as tf

# Input tensor of any shape
input_tensor = tf.random.normal([8, 16])

# First reshape operation changing the shape
t1 = tf.reshape(input_tensor, [4, 32])

# Second reshape operation reverting to the original shape
t2 = tf.reshape(t1, [8, 16])
```
In this example, `t2` will effectively have the same shape as `input_tensor` after the two reshape operations. This pattern triggers the `ReshapeReshapeForwarding` optimization, which recognizes that `t2` is a redundant operation and can be optimized out to directly use `input_tensor`.

### Optimization Pass: `WhileLoopExpensiveInvariantCodeMotion`

#### Characteristics of a TensorFlow Model That Triggers This Optimization:

The `WhileLoopExpensiveInvariantCodeMotion` optimization is triggered when the model includes a `tf.while_loop` with operations inside the loop body that are invariant (i.e., their outputs do not change across iterations of the loop) and are also expensive to compute. The characteristics include:

1. **Use of `tf.while_loop`:** The model must use a TensorFlow while loop.
2. **Invariant and Expensive Operations:** There are operations within the loop body whose outputs do not depend on the loop variables (making them invariant) and are computationally expensive.
3. **Non-Tuple State:** The loop state is not a tuple.
4. **No Side Effects or Control Dependencies:** The invariant operations should not have side effects and should not be involved in control dependencies.
5. **Potential for Hoisting:** The invariant operations are candidates for hoisting out of the loop to avoid redundant computations across iterations.

**Code Illustration:**
```python
import tensorflow as tf

def loop_body(x):
    # An expensive invariant operation
    y = tf.linalg.inv(tf.random.normal([1024, 1024]))  # Expensive and invariant
    return x + y

# Initial value for the loop variable
initial_value = tf.constant(0.0)

# While loop in TensorFlow
result = tf.while_loop(
    cond=lambda i: i < 10,
    body=loop_body,
    loop_vars=[initial_value]
)
```
In this example, the matrix inversion is expensive but invariant since it does not depend on the loop variable `i`. The `WhileLoopExpensiveInvariantCodeMotion` optimization would attempt to hoist such operations outside the loop to improve performance by reducing redundant calculations.