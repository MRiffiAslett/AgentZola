### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `ReshapeReshapeForwarding` in TensorFlow XLA.

# Description
The model should contain the following pattern:
```
t1 = tf.reshape(input_tensor, ...)
t2 = tf.reshape(t1, input_tensor.shape)
```
The pattern describes that there are two reshape operators in the model. The first `reshape` operator transforms a tensor input `input_tensor` from `input_tensor.shape` to any new shape, and the second `reshape` operator transforms the output of first `reshape` back to `input_tensor.shape`.


# Model
class Model(tf.keras.Model):

  def __init__(self):
    super(Model, self).__init__()

  def call(self, x1):
    x2 = tf.reshape(x1, [2,2])
    return tf.reshape(x2, [4])

# Initializing the model
m = Model()

# Inputs to the model
input_shape = [4]
x1 = tf.constant([4.,5.,6.,7.], shape=input_shape)

# Call model
y = m(x1)




### Characteristics of the TensorFlow Model for `ReshapeReshapeForwarding` Optimization:

The `ReshapeReshapeForwarding` optimization pass triggers when a TensorFlow model has sequential reshape operations where the output shape of the second reshape operation is identical to the input shape of the first reshape operation. This scenario effectively means that the two reshapes cancel each other out, creating an opportunity for optimization.

**Model Pattern:**
```python
import tensorflow as tf

# Input tensor
input_tensor = tf.random.normal([8, 8])

# First reshape operation (can be any shape transformation)
t1 = tf.reshape(input_tensor, [64])

# Second reshape operation that reverts t1 to the original shape of input_tensor
t2 = tf.reshape(t1, [8, 8])

# Usage of t2 in further model operations
output = tf.nn.relu(t2)
```

In this example, `t1` is reshaped to [64], and `t2` is reshaped back to [8, 8], which is the original shape of `input_tensor`. This triggers the `ReshapeReshapeForwarding` to optimize out the unnecessary reshape operations.

### Characteristics of the TensorFlow Model for `AllReduceCombiner` Optimization:

The `AllReduceCombiner` optimization is applicable when the model contains multiple `AllReduce` operations that can be combined into a single `AllReduce` operation. This is beneficial in distributed training where reducing the number of `AllReduce` operations can decrease communication overhead and improve performance.

**Model Characteristics:**
- Multiple `AllReduce` operations in the model.
- The operations must have the same reduction operation (e.g., sum, max).
- The operations should not be constrained by specific data layouts.
- The combined size of the tensors involved in the `AllReduce` operations must meet specific byte and count thresholds set by the optimization configuration.

**Model Example with Potential for Optimization:**
```python
import tensorflow as tf

# Input tensors distributed across a cluster
tensor_a = tf.random.normal([1024])
tensor_b = tf.random.normal([1024])

# AllReduce operations
reduced_a = tf.raw_ops.AllReduce(input=tensor_a, reduction='sum', group_size=4)
reduced_b = tf.raw_ops.AllReduce(input=tensor_b, reduction='sum', group_size=4)

# Further computation using reduced tensors
result = reduced_a + reduced_b
```

In this case, if `reduced_a` and `reduced_b` are eligible and meet the thresholds, the `AllReduceCombiner` can combine these two operations into a single `AllReduce` operation, enhancing the efficiency of the distributed computation. The combined operation effectively reduces the overhead of separate synchronization points for `tensor_a` and `tensor_b`.