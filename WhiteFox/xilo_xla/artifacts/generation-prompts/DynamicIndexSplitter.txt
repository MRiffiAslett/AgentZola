### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `DynamicIndexSplitter` in TensorFlow XLA.

# Description
The TensorFlow XLA optimization pass `DynamicIndexSplitter` is triggered by specific characteristics in a TensorFlow model that uses dynamic slicing (`DynamicSlice`) or dynamic updating slicing (`DynamicUpdateSlice`) operations. Here's a concise guide on the model characteristics that would lead to this optimization being applied:

1. **Use of Dynamic Slicing or Dynamic Update Slicing Operations**:
    - The model must contain at least one `DynamicSlice` or `DynamicUpdateSlice` operation. These operations dynamically select a slice or update a slice of a tensor, respectively, based on runtime index values.

2. **Non-scalar Index Operand with Multiple Dimensions**:
    - The index operand (the tensor providing the indices for slicing) should be non-scalar with exactly one dimension. If the index operand is scalar or has more than one dimension, the optimization pass will not modify that operation.

3. **Rank of Operand**:
    - The operand being sliced or updated (i.e., the tensor from which a slice is taken or to which a slice is updated) must have at least one dimension. If this tensor is rank 0 (scalar), the operation is directly replaced with the operand or the update value, which also results in optimization but through a different mechanism.

### Code Example Illustrating Trigger Conditions:
Here's an example TensorFlow model in Python that would trigger the `DynamicIndexSplitter` optimization when compiled with XLA:

```python
import tensorflow as tf

# Assume we're using a shape that ensures the tensor has multiple dimensions
tensor_to_slice = tf.random.uniform([10, 20, 30], dtype=tf.float32)
update_values = tf.random.uniform([2, 3, 4], dtype=tf.float32)  # For DynamicUpdateSlice

# Indices are provided by a 1D tensor, which is not scalar and has exactly one dimension
indices = tf.constant([1, 2, 3], dtype=tf.int32)

# Dynamic Slice Operation
dynamic_slice = tf.slice(tensor_to_slice, indices, [2, 3, 4])

# Dynamic Update Slice Operation
dynamic_update_slice = tf.tensor_scatter_nd_update(tensor_to_slice, tf.reshape(indices, [1, 3]), update_values)

# When compiled with XLA, the DynamicIndexSplitter optimization would be triggered for these operations
```

In this example, both the `tf.slice` (which corresponds to `DynamicSlice` in XLA) and `tf.tensor_scatter_nd_update` (which corresponds to `DynamicUpdateSlice` in XLA) are set up in a way that matches the conditions outlined above. The indices tensor is non-scalar and has exactly one dimension, and the tensors being operated on are not rank 0, making them suitable for this specific optimization.
