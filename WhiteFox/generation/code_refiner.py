"""
Code refining utilities.

Handles parsing generated code from LLM outputs and ensuring required imports.
"""

import re
from generation.code_processor import process_code


def parse_generated_code(generated_text: str) -> str:
    """
    Parse generated code from LLM output.
    Extracts Python code from markdown code blocks or returns cleaned text.
    
    Args:
        generated_text: Raw text generated by the LLM
        
    Returns:
        Cleaned Python code string
    """
    # Try to extract code from markdown code blocks
    # Look for ```python or ``` code blocks
    code_block_pattern = r'```(?:python)?\s*\n(.*?)\n```'
    matches = re.findall(code_block_pattern, generated_text, re.DOTALL)
    
    if matches:
        # If we found code blocks, use the last one (most likely to be complete)
        code = matches[-1].strip()
    else:
        # If no code blocks found, return the text as-is but strip common prefixes/suffixes
        text = generated_text.strip()
        
        # Remove common instruction prefixes that LLMs might add
        prefixes_to_remove = [
            "Here is the code:",
            "Here's the code:",
            "Here is a TensorFlow model:",
            "Here's a TensorFlow model:",
        ]
        
        for prefix in prefixes_to_remove:
            if text.lower().startswith(prefix.lower()):
                text = text[len(prefix):].strip()
                break
        
        code = text
    
    # Filter out non-code lines (requirement text that LLM accidentally included)
    # Remove lines that are clearly English explanations, not Python
    filtered_lines = []
    for line in code.split('\n'):
        stripped = line.strip()
        
        # Skip empty lines (preserve them)
        if not stripped:
            filtered_lines.append(line)
            continue
            
        # Preserve comments
        if stripped.startswith('#'):
            filtered_lines.append(line)
            continue
        
        # Skip lines with ellipsis that are not part of valid Python syntax
        # Common in LLM output like: "...from some_module import ..."
        if '...' in stripped:
            # Check if it's actual Ellipsis literal in valid Python or prose
            # Valid: "..." as the only token, or in docstrings
            is_valid_ellipsis = (
                stripped == '...' or  # Standalone ellipsis
                (stripped.startswith('"""') or stripped.startswith("'''"))  # In docstring
            )
            if not is_valid_ellipsis:
                # Check if it's prose with ellipsis
                if ' ... ' in stripped or stripped.startswith('...'):
                    # Looks like prose with ellipsis, skip it
                    continue
        
        # Skip markdown table syntax
        if stripped.startswith('|') and '|' in stripped[1:]:
            continue
        
        # Skip lines with backticks (markdown code references)
        # These often cause unterminated string literal errors
        if '`' in stripped and not (stripped.startswith("'") or stripped.startswith('"')):
            # Check if it's in a comment or likely prose
            if not stripped.startswith('#'):
                # This is likely prose with code references like "Where `input_shape` is..."
                continue
        
        # Skip lines that are clearly English prose
        # These patterns catch common documentation text
        prose_indicators = [
            'where `',  # "Where `input_shape` is..."
            'this example',  # "This example illustrates..."
            'this test',  # "This test accepts..."
            'the optimization',
            'this optimization',
            'could return',
            'even though',
            'described above',
            'because it checks',
            'cpu and gpu',
            'memory of',
            ' api ',
            'description',
            'note that',
            'note:',
            'example:',
            'usage:',
            'the shape',
            'the tensor',
            'accepts a',
            'argument that',
            'used to',
        ]
        
        is_prose = any(indicator in stripped.lower() for indicator in prose_indicators)
        
        # Also check for sentences (starts with capital, contains spaces, ends with period)
        # but allow valid Python that might look sentence-like
        # Check if line has Python keywords or operators that indicate it's code
        has_code_indicators = any(indicator in stripped for indicator in [
            'def ', 'class ', 'import ', 'from ', 'return ', 
            ' = ', '(', '[', '{', ')', ']', '}',
            'if ', 'else:', 'elif ', 'for ', 'while ',
            'try:', 'except ', 'finally:', 'with ',
            '@', 'lambda ', 'yield ', 'async ', 'await '
        ])
        
        if (is_prose or (
            len(stripped) > 20 and
            stripped[0].isupper() and
            ' ' in stripped and
            not has_code_indicators and
            not stripped.endswith(':')
        )):
            # Skip this line - it's prose, not code
            continue
        
        filtered_lines.append(line)
    
    return '\n'.join(filtered_lines)


def ensure_imports(code: str) -> str:
    """
    Ensure required imports are present in the code.
    
    Adds:
    - import tensorflow as tf (if tf is used but not imported)
    - import numpy as np (if np is used but not imported)
    """
    lines = code.split('\n')
    
    uses_tf = re.search(r'\btf\.', code) or 'tf.' in code or 'tf ' in code
    uses_np = re.search(r'\bnp\.', code) or 'np.' in code or 'np ' in code
    
    has_tf_import = re.search(r'import\s+tensorflow\s+as\s+tf', code, re.IGNORECASE)
    has_np_import = re.search(r'import\s+numpy\s+as\s+np', code, re.IGNORECASE)
    
    imports_to_add = []
    if uses_tf and not has_tf_import:
        imports_to_add.append('import tensorflow as tf')
    if uses_np and not has_np_import:
        imports_to_add.append('import numpy as np')
    
    if imports_to_add:
        insert_idx = 0
        for i, line in enumerate(lines):
            stripped = line.strip()
            if stripped and not stripped.startswith('#'):
                insert_idx = i
                break
        
        for imp in reversed(imports_to_add):
            lines.insert(insert_idx, imp)
        
        code = '\n'.join(lines)
    
    return code


def refine_generated_code(generated_text: str) -> str:
    """
    Complete pipeline for refining generated code.
    
    This combines all refinement steps:
    1. Parse code from LLM output (extract from markdown, etc.)
    2. Ensure required imports are present
    3. Apply WhiteFox code processing (AST transformation)
    
    Args:
        generated_text: Raw text generated by the LLM
        
    Returns:
        Fully processed executable code with input_data variable
    """
    # 1. Parse code from LLM output
    parsed_code = parse_generated_code(generated_text)
    
    # 2. Ensure imports are present
    code_with_imports = ensure_imports(parsed_code)
    
    # 3. Apply WhiteFox code processing (AST transformation)
    processed_code = process_code(code_with_imports)
    
    return processed_code

